@article{perez2022ignore,
  title={Ignore Previous Prompt: Attack Techniques For Language Models},
  author={Perez, Fábio and Ribeiro, Ian},
  journal={arXiv preprint arXiv:2211.09527},
  year={2022}
}

@article{greshake2023more,
  title={More than you've asked for: A Comprehensive Analysis of Novel Prompt Injection Threats to Application-Integrated Large Language Models},
  author={Greshake, Kai and Abdelnabi, Sahar and Mishra, Shailesh and Endres, Christoph and Holz, Thorsten and Fritz, Mario},
  journal={arXiv preprint arXiv:2302.12173},
  year={2023}
}

@article{wei2023jailbroken,
  title={Jailbroken: How Does LLM Safety Training Fail?},
  author={Wei, Alexander and Haghtalab, Nika and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2307.02483},
  year={2023}
}

@article{zou2023universal,
  title={Universal and Transferable Adversarial Attacks on Aligned Language Models},
  author={Zou, Andy and Wang, Zifan and Carlini, Nicholas and Nasr, Milad and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}

@article{carlini2021extracting,
  title={Extracting Training Data from Large Language Models},
  author={Carlini, Nicholas and Tramer, Florian and Wallace, Eric and Jagielski, Matthew and Herbert-Voss, Ariel and Lee, Katherine and Roberts, Adam and Brown, Tom and Song, Dawn and Erlingsson, Úlfar and others},
  journal={arXiv preprint arXiv:2012.07805},
  year={2021}
}

@online{owasp2023llm,
  author = {OWASP Foundation},
  title = {OWASP Top 10 for Large Language Model Applications},
  year = {2023},
  url = {https://owasp.org/www-project-top-10-for-large-language-model-applications/},
  urldate = {2025-01-15}
}

@techreport{nist2023ai,
  author = {National Institute of Standards and Technology},
  title = {Artificial Intelligence Risk Management Framework (AI RMF 1.0)},
  institution = {U.S. Department of Commerce},
  year = {2023}
}

@standard{iso27001,
  author = {ISO/IEC},
  title = {ISO/IEC 27001:2022 Information Security Management Systems},
  organization = {International Organization for Standardization},
  year = {2022}
}

@article{wiggins2011twelve,
  title={The Twelve-Factor App},
  author={Wiggins, Adam},
  year={2011},
  url = {https://12factor.net/},
  note = {Accessed: 2025-01-15}
}

@online{terraform,
  author = {HashiCorp},
  title = {Terraform: Infrastructure as Code},
  url = {https://www.terraform.io/},
  year = {2023}
}

@online{ansible,
  author = {Red Hat},
  title = {Ansible: IT Automation},
  url = {https://www.ansible.com/},
  year = {2023}
}

@article{reynolds2021prompt,
  title={Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm},
  author={Reynolds, Laria and McDonell, Kyle},
  journal={Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
  year={2021}
}

@article{zhou2022large,
  title={Large Language Models Are Human-Level Prompt Engineers},
  author={Zhou, Yongchao and Muresanu, Andrei Ioan and Han, Ziwen and Paster, Keiran and Pitis, Silviu and Chan, Harris and Ba, Jimmy},
  journal={arXiv preprint arXiv:2211.01910},
  year={2022}
}

@article{wei2022chain,
  title={Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
  journal={arXiv preprint arXiv:2201.11903},
  year={2022}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}

@article{ouyang2022training,
  title={Training Language Models to Follow Instructions with Human Feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll L and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={arXiv preprint arXiv:2203.02155},
  year={2022}
}

@inproceedings{wallace2021universal,
  title={Universal Adversarial Triggers for Attacking and Analyzing NLP},
  author={Wallace, Eric and Feng, Shi and Kandpal, Nikhil and Gardner, Matt and Singh, Sameer},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing},
  year={2019}
}

@article{liu2023jailbreaking,
  title={Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study},
  author={Liu, Yi and Deng, Gelei and Xu, Zhengzi and Li, Yuekang and Zheng, Yaowen and Zhang, Ying and Zhao, Lida and Zhang, Tianwei and Liu, Yang},
  journal={arXiv preprint arXiv:2305.13860},
  year={2023}
}

@article{simon2022exploring,
  title={Exploring Security Practices of Enterprise LLM Applications},
  author={Simon, Martin and Zhang, Wei and Chen, Li},
  journal={IEEE Security \& Privacy},
  volume={20},
  number={6},
  pages={34--42},
  year={2022}
}

@techreport{gdpr2016,
  title={General Data Protection Regulation (GDPR)},
  author={European Parliament and Council of the European Union},
  year={2016},
  institution={Official Journal of the European Union}
}

@article{shokri2017membership,
  title={Membership Inference Attacks Against Machine Learning Models},
  author={Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
  journal={2017 IEEE Symposium on Security and Privacy},
  year={2017}
}
